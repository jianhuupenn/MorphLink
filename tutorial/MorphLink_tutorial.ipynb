{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>MorphLink Tutorial</center></h1>\n",
    "\n",
    "\n",
    "<center>Author: Jing Huang, Chenyang Yuan, Jiahui Jiang, Jianfeng Chen, Sunil S. Badve, Yesim Gokmen-Polar, Rossana L. Segura, Xinmiao Yan, Alexander Lazar, Jianjun Gao, Michael Epstein, Linghua Wang* and Jian Hu*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outline\n",
    "1. Installation\n",
    "2. Import modules\n",
    "3. Read in data\n",
    "4. Image segmentation\n",
    "5. Extract interpretable image features\n",
    "6. Link image features with gene expression\n",
    "7. Select samples for visual demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Installation\n",
    "To install MorphLink package you must make sure that your python version is over 3.5. If you donâ€™t know the version of python you can check it by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "platform.python_version()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Because MorphLink depends on pytorch, you should make sure that torch is correctly installed.\n",
    "<br>\n",
    "Now you can install the current release of MorphLink by the following three ways:\n",
    "#### 1.1 PyPI: Directly install the package from PyPI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip3 install MorphLink\n",
    "# Note: you need to make sure that the pip is for python3\n",
    "\n",
    "# or we could install MorphLink by\n",
    "python3 -m pip install MorphLink\n",
    "\n",
    "# If you do not have permission (when you get a permission denied error), you should install MorphLink by\n",
    "pip3 install --user MorphLink"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Github\n",
    "Download the package from Github and install it locally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "git clone https://github.com/jianhuupenn/MorphLink\n",
    "cd MorphLink/MorphLink_package/\n",
    "python3 setup.py install --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Anaconda\n",
    "If you do not have Python3.5 or Python3.6 installed, consider installing Anaconda (see Installing Anaconda). After installing Anaconda, you can create a new environment, for example, MorphLink_env (or any name that you like)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an environment called MorphLink_env\n",
    "conda create -n MorphLink_env python=3.7.9\n",
    "\n",
    "# activate your environment \n",
    "conda activate MorphLink_env\n",
    "git clone https://github.com/jianhuupenn/MorphLink\n",
    "cd MorphLink/MorphLink_package/\n",
    "python3 setup.py build\n",
    "python3 setup.py install\n",
    "conda deactivate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Import python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,csv,time,re,pickle,argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import numba\n",
    "import anndata as ad\n",
    "from anndata import AnnData,read_csv,read_text,read_mtx\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy import ndimage\n",
    "from scipy.sparse import issparse\n",
    "import scanpy as sc\n",
    "# import SpaGCN as spg\n",
    "import MorphLink as mph\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from skimage import io\n",
    "from skimage.util import img_as_ubyte\n",
    "from skimage.measure import regionprops\n",
    "from skimage.feature import graycomatrix, graycoprops, peak_local_max\n",
    "from skimage.segmentation import watershed\n",
    "import matplotlib.colors as clr\n",
    "import matplotlib.pyplot as plt\n",
    "import imutils\n",
    "import slideio\n",
    "import cv2\n",
    "os.environ[\"OPENCV_IO_MAX_IMAGE_PIXELS\"] = str(pow(2,40)) # os system settings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mph.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Read in data\n",
    "The current version of MorphLink requres two input data: \n",
    "<br>\n",
    "1. The gene expression matrix (N $\\times$ G): expression_matrix.h5ad;\n",
    "<br>\n",
    "The gene expression data here is stored as an AnnData object. AnnData stores a data matrix .X together with annotations of observations .obs, variables .var and unstructured annotations .uns.\n",
    "<br>\n",
    "2. Histology image: histology.jpg (can be .tif or .png or .jpg).\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the working directory\n",
    "plot_dir=\".\" # set a data directory (need to make up folders of results, seg_results, and figures)\n",
    "if not os.path.exists(plot_dir+\"/figures\"):\n",
    "\tos.mkdir(plot_dir+\"/figures\")\n",
    "\n",
    "\n",
    "if not os.path.exists(plot_dir+\"/results\"):\n",
    "\tos.mkdir(plot_dir+\"/results\")\n",
    "\n",
    "\n",
    "if not os.path.exists(plot_dir+\"/seg_results\"):\n",
    "\tos.mkdir(plot_dir+\"/seg_results\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in gene expression adata\n",
    "gene_adata=sc.read(\"./toy_data/exp_tumor.h5ad\")\n",
    "\n",
    "# Read in histology image\n",
    "img=cv2.imread(\"./toy_data/img_tumor.jpg\")\n",
    "d0, d1=img.shape[0], img.shape[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Image segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Determine patch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- patch_size varies with datasets generated from different techniques (default value for 10x Visium is 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the patch size\n",
    "patch_size=400\n",
    "half_size=patch_size/2\n",
    "\n",
    "# spatial coordinates of spots\n",
    "pixel_x=gene_adata.obs[\"pixel_x\"].tolist()\n",
    "pixel_y=gene_adata.obs[\"pixel_y\"].tolist()\n",
    "\n",
    "# Test the patch size \n",
    "img_new=img.copy()\n",
    "for i in range(len(pixel_x)):\n",
    "\tx=pixel_x[i]\n",
    "\ty=pixel_y[i]\n",
    "\timg_new[int(x-half_size):int(x+half_size), int(y-half_size):int(y+half_size),:]=0\n",
    "\n",
    "\n",
    "img_new=cv2.resize(img_new, (2000, 2000), interpolation = cv2.INTER_AREA)\n",
    "img_new_cvt=cv2.cvtColor(img_new, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img_new_cvt)\n",
    "plt.show()\n",
    "# save the test patch size image\n",
    "cv2.imwrite(plot_dir+'/figures/test_patch_size.jpg', img_new)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Patch split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- patches: a 4D array with a shape of (N, m, m, 3), where N stands for the total number of spots and m denotes the specified patch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches=mph.patch_split_for_ST(img=img, patch_size=patch_size, spot_info=gene_adata.obs, x_name=\"pixel_x\", y_name=\"pixel_y\")\n",
    "# spot information\n",
    "patch_info=gene_adata.obs \n",
    "patch_info[\"x\"]=patch_info[\"pixel_x\"]\n",
    "patch_info[\"y\"]=patch_info[\"pixel_y\"]\n",
    "\n",
    "# Save the splitted image patches and its patch_info\n",
    "patch_info.to_csv(plot_dir+\"/results/patch_info.csv\")\n",
    "np.save(plot_dir+\"/results/patches.npy\", patches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches=np.load(plot_dir+\"/results/patches.npy\")\n",
    "patch_info=pd.read_csv(plot_dir+\"/results/patch_info.csv\", header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Segment each patch into masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- n_clusters: equals to the number of masks within each patch (default value is 10) \n",
    "- refine the initial K-Means clusters by a convolution layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a K-Means clustering to divide the pixels of each image patch into clusters \n",
    "# then employ a convolution layer to refine the cluster assignment\n",
    "mph.step4_Segmentation(plot_dir=plot_dir, n_clusters=10, refine=True, refine_threshold=4) # take around 2h\n",
    "check_dic_list(plot_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 Match masks across patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- num_mask_each: the number of masks within each patch (default value is 10)\n",
    "- mapping_threshold1: max single color channel difference, choose all channels\n",
    "- mapping_threshold2: max single color channel difference, choose one channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify shared clusters across patches based on color distance\n",
    "num_mask_each=10\n",
    "mapping_threshold1=30  # max single color channel difference, choose all channels\n",
    "mapping_threshold2=60  # max single color channel difference, choose one channel\n",
    "masks, masks_index=mph.step5_Extract_Masks(plot_dir=plot_dir, patch_size=patch_size, num_mask_each=num_mask_each, mapping_threshold1=mapping_threshold1, mapping_threshold2=mapping_threshold2)\n",
    "\n",
    "# Plot the segmentated masks\n",
    "mph.step6_Plot_Masks(plot_dir=plot_dir, d0=d0, d1=d1, masks=masks, patch_size=patch_size, mapping_threshold1=mapping_threshold1, mapping_threshold2=mapping_threshold2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Extract interpretable image features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Mask-level image features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_mask_each=10\n",
    "mapping_threshold1=30  # max single color channel difference, choose all channels\n",
    "mapping_threshold2=60 \n",
    "masks=np.load(plot_dir+\"/results/masks_\"+str(mapping_threshold1)+\"_\"+str(mapping_threshold2)+\".npy\")\n",
    "with open(plot_dir+\"/results/masks_index_\"+str(mapping_threshold1)+\"_\"+str(mapping_threshold2)+\".pkl\", \"rb\") as f:\n",
    "\tmasks_index = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret=mph.Extract_Whole_Mask_Features(masks, patch_info)\n",
    "ret_logged=mph.Selective_Log_Transfer(ret)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ret_logged.head()) # mask-level image features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the extracted mask-level image features\n",
    "ret=sc.AnnData(ret.values,obs=patch_info, var=pd.DataFrame({\"feature_names\":ret.columns.tolist()}))\n",
    "ret.var.index=ret.var[\"feature_names\"].tolist()\n",
    "ret_logged=sc.AnnData(ret_logged.values,obs=patch_info, var=pd.DataFrame({\"feature_names\":ret_logged.columns.tolist()}))\n",
    "ret_logged.var.index=ret_logged.var[\"feature_names\"].tolist()\n",
    "ret_logged.write_h5ad(plot_dir+\"/results/mask_features_all_logged.h5ad\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Object-level image features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the connected components within each mask\n",
    "mph.step8_CC_Detection_for_ST(plot_dir=plot_dir, patch_info=patch_info, masks_selected=masks, masks_index_selected=masks_index, details=False)\n",
    "\n",
    "# Summarize image features for connected components by patch\n",
    "labels=np.load(plot_dir+\"/results/cc_no_details.npy\")\n",
    "channels=[i for i in range(labels.shape[0])]\n",
    "ret=mph.Extract_CC_Features(labels=labels, patch_info=patch_info, channels=channels, min_area=10)\n",
    "ret_logged=mph.Selective_Log_Transfer(ret)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ret_logged.head()) # object-level image features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the extracted object-level image features\n",
    "ret=sc.AnnData(ret.values,obs=patch_info, var=pd.DataFrame({\"feature_names\":ret.columns.tolist()}))\n",
    "ret.var.index=ret.var[\"feature_names\"].tolist()\n",
    "ret_logged=sc.AnnData(ret_logged.values,obs=patch_info, var=pd.DataFrame({\"feature_names\":ret_logged.columns.tolist()}))\n",
    "ret_logged.var.index=ret_logged.var[\"feature_names\"].tolist()\n",
    "ret_logged.write_h5ad(plot_dir+\"/results/cc_features_all_logged.h5ad\")\n",
    "\n",
    "# Combine mask-level image features with object-level image features\n",
    "sub1=sc.read(plot_dir+\"/results/mask_features_all_logged.h5ad\")\n",
    "sub2=sc.read(plot_dir+\"/results/cc_features_all_logged.h5ad\")\n",
    "img_adata=ad.concat([sub1, sub2], axis=1,join='inner')\n",
    "img_adata.obs=sub1.obs\n",
    "del sub1, sub2\n",
    "img_adata.write_h5ad(plot_dir+\"/results/all_features_logged.h5ad\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Understand masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- num_samples: the number of samples for each mask visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the properties of each mask\n",
    "ret=mph.mask_properity(masks, img, patch_info, d0, d1, center=True)\n",
    "print(ret) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some sample masks for visuallization\n",
    "num_samples = 3 # the number of samples for each mask\n",
    "for channel in range(masks.shape[0]):\n",
    "    ret_img=mph.mask_example(channel, img_adata, patch_info, patches, masks, plot_dir=plot_dir+\"/figures\", num_samples=num_samples, filter_mask_area=True)\n",
    "    ret_img_cvt=cv2.cvtColor(ret_img, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(ret_img_cvt)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Link image features with gene expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1 Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gene expression\n",
    "gene_adata=sc.read(\"./toy_data/exp_tumor.h5ad\")\n",
    "gene_adata.X=(np.array(gene_adata.X.A) if issparse(gene_adata.X) else np.array(gene_adata.X))\n",
    "sc.pp.log1p(gene_adata)\n",
    "\n",
    "# Histology image\n",
    "img_adata=sc.read(plot_dir+\"/results/all_features_logged.h5ad\")\n",
    "img_adata.X=(img_adata.X.A if issparse(img_adata.X) else img_adata.X)\n",
    "img_adata=img_adata[img_adata.obs.index.isin(gene_adata.obs.index)]\n",
    "# Keep image features with over 10% non median \n",
    "img_adata=img_adata[:, np.sum(img_adata.X!=np.median(img_adata.X, 0), 0)>(img_adata.shape[0]/10)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2 Spatial clustering on gene expression and image features separately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from louvain clustering, other spatial clustering methods (e.g., SpaGCN) can also be employed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set colors\n",
    "cnt_color = clr.LinearSegmentedColormap.from_list('pink_green', ['#3AB370',\"#EAE7CC\",\"#FD1593\"], N=256)\n",
    "cat_color=[\"#F56867\",\"#FEB915\",\"#C798EE\",\"#59BE86\",\"#7495D3\",\"#D1D1D1\",\"#6D1A9C\",\"#15821E\",\"#3A84E6\",\"#997273\",\"#787878\",\"#DB4C6C\",\"#9E7A7A\",\"#554236\",\"#AF5F3C\",\"#93796C\",\"#F9BD3F\",\"#DAB370\",\"#877F6C\",\"#268785\"]\n",
    "\n",
    "# Gene expression\n",
    "# Louvain clustering\n",
    "pca = PCA(n_components=50)\n",
    "pca.fit(gene_adata.X)\n",
    "embed=pca.transform(gene_adata.X)\n",
    "tmp=sc.AnnData(embed)\n",
    "sc.pp.neighbors(tmp, n_neighbors=10)\n",
    "sc.tl.louvain(tmp,resolution=0.05)\n",
    "y_pred=tmp.obs['louvain'].astype(int).to_numpy()\n",
    "gene_adata.obs[\"gene_pred\"]=y_pred\n",
    "# or by SpaGCN\n",
    "gene_adata.obs[\"gene_pred\"]=gene_adata.obs[\"spagcn_pred\"].astype('category') # use the spatial clustering results from SpaGCN\n",
    "\n",
    "# check spatial clustering of gene expression\n",
    "domains=\"gene_pred\"\n",
    "num_domains=len(gene_adata.obs[domains].unique())\n",
    "gene_adata.uns[domains+\"_colors\"]=list(cat_color[:num_domains])\n",
    "ax=sc.pl.scatter(gene_adata,alpha=1,x=\"pixel_y\",y=\"pixel_x\",color=domains,title=domains,color_map=cat_color,show=False,size=150000/gene_adata.shape[0])\n",
    "ax.set_aspect('equal', 'box')\n",
    "ax.axes.invert_yaxis()\n",
    "plt.savefig(plot_dir+\"/figures/gene_pred.png\", dpi=600)\n",
    "plt.show()\n",
    "plt.close()\n",
    "# ax=spg.plot_spatial_domains_ez_mode(gene_adata, domain_name=\"gene_pred\", x_name=\"pixel_y\", y_name=\"pixel_x\", plot_color=cat_color, size=150000/gene_adata.shape[0], \n",
    "\t# show=False, save=True,save_dir=plot_dir+\"/figures/gene_pred.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image features\n",
    "# Louvain clustering\n",
    "pca = PCA(n_components=50)\n",
    "pca.fit(img_adata.X)\n",
    "embed=pca.transform(img_adata.X)\n",
    "tmp=sc.AnnData(embed)\n",
    "sc.pp.neighbors(tmp, n_neighbors=10)\n",
    "sc.tl.louvain(tmp,resolution=0.05)\n",
    "y_pred=tmp.obs['louvain'].astype(int).to_numpy()\n",
    "len(np.unique(y_pred)) # number of louvain clusters for image features\n",
    "img_adata.obs[\"img_pred\"]=y_pred\n",
    "img_adata.obs[\"img_pred\"]=img_adata.obs[\"img_pred\"].astype('category')\n",
    "\n",
    "# check spatial clustering of image features\n",
    "domains=\"img_pred\"\n",
    "num_domains=len(img_adata.obs[domains].unique())\n",
    "img_adata.uns[domains+\"_colors\"]=list(cat_color[:num_domains])\n",
    "ax=sc.pl.scatter(img_adata,alpha=1,x=\"pixel_y\",y=\"pixel_x\",color=domains,title=domains,color_map=cat_color,show=False,size=150000/img_adata.shape[0])\n",
    "ax.set_aspect('equal', 'box')\n",
    "ax.axes.invert_yaxis()\n",
    "plt.savefig(plot_dir+\"/figures/img_pred.png\", dpi=600)\n",
    "plt.show()\n",
    "plt.close()\n",
    "# ax=spg.plot_spatial_domains_ez_mode(img_adata, domain_name=\"img_pred\", x_name=\"pixel_y\", y_name=\"pixel_x\", plot_color=cat_color,size=180000/img_adata.shape[0], \n",
    "\t# show=False, save=True,save_dir=plot_dir+\"/figures/img_pred.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3 Identify subregions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check spatial clustering of combined clusters\n",
    "gene_clusters=gene_adata.obs[\"gene_pred\"].tolist()\n",
    "img_clusters=img_adata.obs[\"img_pred\"].tolist()\n",
    "\n",
    "# for any cluster pair if the overlapping spots / overall spots > max_threshod (default value is 0.2) then merge the two clusters\n",
    "gene_adata.obs[\"combined_pred\"]=mph.combine_clusters(gene_clusters, img_clusters, min_threshold=1/5, max_threshold=1/2)\n",
    "gene_adata.obs[\"combined_pred\"]=gene_adata.obs[\"combined_pred\"].astype('category')\n",
    "# ax=spg.plot_spatial_domains_ez_mode(gene_adata, domain_name=\"combined_pred\", x_name=\"pixel_y\", y_name=\"pixel_x\", plot_color=cat_color,size=150000/gene_adata.shape[0], \n",
    "\t# show=False, save=True,save_dir=plot_dir+\"/figures/combined.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4 Quantify the curve-based similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- genes: a set of interested genes or identified from DE analysis\n",
    "- channel: the mask channel number to focus on\n",
    "- w_cor: the weights for correlation (default value is 0.5)\n",
    "- CPSI: Curve-based Pattern Similarity Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a set of interested genes (or from DE analysis)\n",
    "genes=[\"B2M\", \"CD74\", \"TAP1\", \"MKI67\", \"MYCL\", \"TUBB\", \"MS4A1\", \"IGHM\"]\n",
    "gene_adata_sub=gene_adata[:,gene_adata.var.index.isin(genes)].copy()\n",
    "\n",
    "# Specify the mask channel \n",
    "channel = 4\n",
    "features=[i for i in img_adata.var.index if \"m\"+str(channel) in i]+[i for i in img_adata.var.index if \"c\"+str(channel) in i]\n",
    "img_adata_sub=img_adata[:,img_adata.var.index.isin(features)].copy()\n",
    "\n",
    "# Normalize gene expression and image features to the value range of [0,1]\n",
    "# gene expression\n",
    "gene_df=gene_adata_sub.X.A if issparse(gene_adata_sub.X) else gene_adata_sub.X\n",
    "gene_df=np.array(gene_df)\n",
    "gene_df=(gene_df-np.min(gene_df, 0))/(np.max(gene_df, 0)-np.min(gene_df, 0))\n",
    "# image features\n",
    "img_df=img_adata_sub.X.A if issparse(img_adata_sub.X) else img_adata_sub.X\n",
    "img_df=np.array(img_df)\n",
    "img_df=(img_df-np.min(img_df, 0))/(np.max(img_df, 0)-np.min(img_df, 0))\n",
    "\n",
    "# spatial coordinates of spots\n",
    "x = gene_adata_sub.obs[\"pixel_x\"].values\n",
    "y = gene_adata_sub.obs[\"pixel_y\"].values\n",
    "\n",
    "# Measure the regional pattern similarity\n",
    "clusters=[0]*len(x)\n",
    "cor=mph.pattern_similarity(gene_df, img_df, clusters, x, y, num_interval=20, method=\"mean\", metric=\"cor\", integrate_xy=\"weighted\",pool=\"min\", rescale=True, add_noise=True, two_side=False, min_spots=5)\n",
    "diff=mph.pattern_similarity(gene_df, img_df, clusters, x, y, num_interval=20, method=\"mean\", metric=\"diff\", integrate_xy=\"weighted\",pool=\"max\", rescale=True, add_noise=True, two_side=False, min_spots=5)\n",
    "cor=pd.DataFrame(cor, index=gene_adata_sub.var.index, columns=img_adata_sub.var.index)\n",
    "diff=pd.DataFrame(diff, index=gene_adata_sub.var.index, columns=img_adata_sub.var.index)\n",
    "# assign weights to correlation (default value is 0.5)\n",
    "w_cor=1/2\n",
    "CPSI=w_cor*cor+(1-w_cor)*(1-diff)\n",
    "\n",
    "# take gene CD74 as an example\n",
    "# identify 10 image features that share the highest regional pattern similarity with the specified gene\n",
    "g=\"CD74\" # from the list of genes\n",
    "CPSI.loc[g, :].nlargest(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.5 Generate marginal curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a pair of gene expression feature and image feature\n",
    "g=\"CD74\"\n",
    "f=CPSI.loc[g, :].nlargest(1).index.tolist()[0] # select the image feature with the highest regional pattern similarity\n",
    "print(f)\n",
    "\n",
    "# Gradient changes along x-axis and y-axis\n",
    "range_step=1/4\n",
    "num_cuts=5\n",
    "\n",
    "img_adata_sub.obs[g]=np.array(gene_adata_sub.X)[:, gene_adata_sub.var.index==g]\n",
    "img_adata_sub.obs[f]=np.array(img_adata_sub.X)[:, img_adata_sub.var.index==f]\n",
    "x, y, z=[], [], []\n",
    "for i in range(num_cuts):\n",
    "\tmx=np.quantile(img_adata_sub.obs[f], i/num_cuts+1/num_cuts*(1-range_step))\n",
    "\tmi=np.quantile(img_adata_sub.obs[f], i/num_cuts+1/num_cuts*range_step)\n",
    "\tsub_tmp=img_adata_sub[(img_adata_sub.obs[f]>=mi)&(img_adata_sub.obs[f]<=mx),:]\n",
    "\tmedian_f=np.median(sub_tmp.obs[f])\n",
    "\tsamples=sub_tmp.obs.index[(sub_tmp.obs[f]>=mi) & (sub_tmp.obs[f]<=mx)].tolist()\n",
    "\tx.append(np.round(np.mean(sub_tmp.obs[f]), 3))\n",
    "\ty.append(np.round(np.mean(sub_tmp.obs[g]), 3))\n",
    "\tz.append(np.round(np.mean(sub_tmp.obs[f]), 3))\n",
    "\tz.append(np.round(np.mean(sub_tmp.obs[g]), 3))\n",
    "\n",
    "print(g)\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)\n",
    "\n",
    "# generate a scatter plot for x and y\n",
    "plt.scatter(x, y)\n",
    "plt.xlabel(\"gene expression levels\")\n",
    "plt.ylabel(\"image feature levels\")\n",
    "plt.title(\"The regional linkage between \"+g+\" and \"+f)\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Select samples for visual demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- num_sample: the number of samples for demonstrating the linkage between the pair of gene expression feature and image feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=np.load(plot_dir+\"/results/cc_no_details.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load in the generated patch_info, patches, and labels\n",
    "# plot_dir=\".\"\n",
    "# patch_info=pd.read_csv(plot_dir+\"/results/patch_info.csv\", header=0, index_col=0)\n",
    "# patches=np.load(plot_dir+\"/results/patches.npy\")\n",
    "# labels=np.load(plot_dir+\"/results/cc_no_details.npy\")\n",
    "\n",
    "# Specify a set of interested image features\n",
    "target_features = [f]\n",
    "visual_img_list = []\n",
    "num_sample=5\n",
    "\n",
    "for f in target_features:\n",
    "\tif not os.path.exists(plot_dir+\"/figures/\"+f):\n",
    "\t\tos.mkdir(plot_dir+\"/figures/\"+f)\n",
    "\tvisual_img=mph.sample_illustration(f, img_adata_sub, patch_info, patches, labels, plot_dir=plot_dir+\"/figures/\"+f, num_cuts=num_cuts, range_step=range_step, num_sample=num_sample, filter_mask_area=True, filter_cc_q100=False)\n",
    "\tvisual_img_list.append(visual_img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample linkage visual demonstration\n",
    "for i in range(len(visual_img_list)):\n",
    "    visual_img=visual_img_list[i]\n",
    "    visual_img_cvt=cv2.cvtColor(visual_img, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(figsize=(12,36))\n",
    "    plt.imshow(visual_img_cvt)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
